{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('Travel_Survey_Compressed.csv', sep=',')\n",
    "#result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Travel_Survey_Data.csv', 'w')\n",
    "with open('Travel_Survey_Compressed.csv', 'r') as r:\n",
    "    for ln in r:\n",
    "        ln_li = ln.replace(\"\\n\", \"\").replace(\"\\ufeff\",\"\").split(',')\n",
    "        for i in ln_li[0].split(\";\"):\n",
    "            for j in ln_li[2].split(\";\"):\n",
    "                new_ln = i + \",\" + ln_li[1] + \",\" + j.lstrip() + \",\"\n",
    "                new_ln += ln.split(\",\", 3)[3] + \"\\n\"\n",
    "                new_ln = new_ln.replace(\"\\n\\n\", \"\\n\")\n",
    "                #print(new_ln)\n",
    "                f.write(new_ln.lstrip())\n",
    "result_filtered = pd.read_csv('Travel_Survey_Data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_list = result[\"Recommendation\"].tolist()\n",
    "dest_li_unique = list(dict.fromkeys(dest_list))\n",
    "#print(dest_li_unique, len(dest_li_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#favorite activity encoding\n",
    "activity_list = result_filtered[\"Favorite Activity\"].tolist()\n",
    "activity_list = list(dict.fromkeys(activity_list))\n",
    "#print(activity_list)\n",
    "\n",
    "#reason to travel encoding\n",
    "reason_list = result_filtered[\"Main Reason to Travel\"].tolist()\n",
    "reason_list = list(dict.fromkeys(reason_list))\n",
    "\n",
    "#important factor encoding\n",
    "factor_list = result_filtered[\"Most Important Factor for Trip Planning\"].tolist()\n",
    "factor_list = list(dict.fromkeys(factor_list))\n",
    "\n",
    "#appealing destination encoding\n",
    "appeal_list = result_filtered[\"Most Appealing Destination\"].tolist()\n",
    "appeal_list = list(dict.fromkeys(appeal_list))\n",
    "\n",
    "# new csv\n",
    "fw = open(\"Travel_Survey_Data_Encoded.csv\", \"w\")\n",
    "fw.write(\"Recommendation,Ideal Group Size,Openness,Conscientiousness,Extraversion,Agreeableness,Neuroticism,is_student,is_male,is_female,is_non_binary,\")\n",
    "\n",
    "en_text_list = \"\"\n",
    "for act in reason_list + factor_list + activity_list + appeal_list:\n",
    "    en_name = \"is_\" + act.replace(\" \", \"_\").lower()\n",
    "    en_text_list += en_name + \",\"\n",
    "#print(en_text_list[:-1])\n",
    "fw.write(en_text_list[:-1] + \"\\n\")\n",
    "#fw.close()\n",
    "\n",
    "with open('Travel_Survey_Compressed.csv', 'r') as fr:\n",
    "    for ln in fr:\n",
    "        if \"Recommendation\" in ln:\n",
    "            pass\n",
    "        else:\n",
    "            li = ln.lower().split(\",\")\n",
    "            reason = li[0]\n",
    "            factor = li[1]\n",
    "            activity = li[2]\n",
    "            appeal = li[3]\n",
    "            gp_size = li[4]\n",
    "            gender = li[5]\n",
    "            student = li[6]\n",
    "            op, con, ext, agr, neu = li[7:12]\n",
    "            rec = li[12].replace(\"\\n\", \"\").title()\n",
    "            \n",
    "            row = rec + \",\" + gp_size + \",\" + op + \",\" + con + \",\" + ext + \",\" + agr + \",\" + neu + \",\"\n",
    "            if student.strip().lower() == \"yes\":\n",
    "                row += \"1,\"\n",
    "            else:\n",
    "                row += \"0,\"\n",
    "            if gender.strip().lower() == \"male\":\n",
    "                row += \"1,\"\n",
    "            else:\n",
    "                row += \"0,\"\n",
    "            if gender.strip().lower() == \"female\":\n",
    "                row += \"1,\"\n",
    "            else:\n",
    "                row += \"0,\"\n",
    "            if gender.strip().lower() == \"non_binary\":\n",
    "                row += \"1,\"\n",
    "            else:\n",
    "                row += \"0,\"\n",
    "            \n",
    "            #reason\n",
    "            for i in reason_list:\n",
    "                if i.lower() in reason:\n",
    "                    row += \"1,\"\n",
    "                else:\n",
    "                    row += \"0,\"\n",
    "                    \n",
    "            #factor\n",
    "            for i in factor_list:\n",
    "                if i.lower() in factor:\n",
    "                    row += \"1,\"\n",
    "                else:\n",
    "                    row += \"0,\"\n",
    "                    \n",
    "            #activity\n",
    "            for i in activity_list:\n",
    "                if i.lower() in activity:\n",
    "                    row += \"1,\"\n",
    "                else:\n",
    "                    row += \"0,\"\n",
    "                    \n",
    "            #appeal\n",
    "            for i in appeal_list:\n",
    "                if i.lower() in appeal:\n",
    "                    row += \"1,\"\n",
    "                else:\n",
    "                    row += \"0,\"\n",
    "                    \n",
    "            fw.write(row + \"\\n\")\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['ART and ENERGY', 'Art museums/galleries', 'Discover new cuisines',\n",
       "        'FOOD', 'To climb', 'To explore architecture and history',\n",
       "        'To go on an adventure',\n",
       "        'To learn more about a language or a culture',\n",
       "        'To look at and appreciate beautiful places', 'To meet new people',\n",
       "        'To relax and escape work and responsibilities',\n",
       "        'To see the wonders of nature',\n",
       "        'To share travel stories and view with friends and family back home',\n",
       "        'To spend quality time with family/friends', 'Work or business'],\n",
       "       dtype=object),\n",
       " array(['Aesthetic of destination', 'Budget',\n",
       "        'Overall quality of general experience', 'Proximity to nature',\n",
       "        'Proximity to other destinations', 'Safety', 'Time',\n",
       "        'Travel group size', 'Variety of activities at destination',\n",
       "        'Variety of activities at destination but more specifically what climbing is in that area'],\n",
       "       dtype=object),\n",
       " array(['Animals', 'Architecture', 'Art Gallery', 'Banana Plantation',\n",
       "        'Bar', 'Bars', 'Beach', 'Bedouin Camp', 'Bike', 'Boat',\n",
       "        'Boat Trip', 'Broadway', 'Cafes', 'Camel Ride', 'Camp', 'Chill',\n",
       "        'Chocolae Factory', 'Christmas Market', 'Churches', 'Cinema',\n",
       "        'City', 'Climb', 'Clubbing', 'Concert', 'Cook', 'Cooking Class',\n",
       "        'Cottage', 'Countryside', 'Cruise', 'Culture', 'Cycle',\n",
       "        'Dance Workshops', 'Desert', 'Drive', 'Explore', 'Extreme Sports',\n",
       "        'Family', 'Farm', 'Festival', 'Food', 'Friends', 'Gelato',\n",
       "        'Glacier', 'Golf', 'Helicopter Ride', 'Hike', 'History', 'Island',\n",
       "        'Islands', 'Karaoke', 'Kayak', 'Landmark', 'Landmarks',\n",
       "        'Landscapes', 'Market', 'Meet Locals', 'Motorcycle', 'Mountains',\n",
       "        'Mud Bath', 'Museum', 'Nature', 'Nightlife', 'Northern Lights',\n",
       "        'Ocean', 'Old Town', 'Park', 'Party', 'Photography', 'Pool', 'Pub',\n",
       "        'Relax', 'Rivers', 'Road Trip', 'Road Trips', 'Run',\n",
       "        'Rural Heritage', 'Safari', 'Safaris', 'Sandboard', 'Sauna',\n",
       "        'School', 'Science Center', 'Scuba Dive', 'Seaside', 'Shop',\n",
       "        'Shows', 'Sightsee', 'Ski', 'Sky Terrace', 'Skydive', 'Skyscraper',\n",
       "        'Snorkel', 'Snow Hike', 'Snowboard', 'Snowshoe', 'Sport Venues',\n",
       "        'Stargaze', 'Street Food', 'Sulfur Spring', 'Sunbath', 'Sunset',\n",
       "        'Sunshine', 'Surf', 'Swim', 'Tan', 'Tattoo', 'Tea', 'Temple',\n",
       "        'Theatre', 'Tourist Attractions', 'Transit', 'Tubing',\n",
       "        'UN Headquarter', 'University', 'Vegetation', 'View', 'Vineyards',\n",
       "        'Visit Surrounding Areas', 'Volunteer', 'Walk', 'Watch Football',\n",
       "        'Waterfall', 'Waterfalls', 'Wildlife', 'Wine Tasting', 'Zip Line',\n",
       "        'Zoo'], dtype=object),\n",
       " array(['A big metropolitan city', 'A hang gliding ride over a lush field',\n",
       "        'A relaxing day at the beach', 'An all-inclusive resort',\n",
       "        'An old city with interesting architecture',\n",
       "        'An overnight backpacking trip on a volcano'], dtype=object),\n",
       " array([1, 2, 3, 4, 5]),\n",
       " array(['Female', 'Male', 'Non_Binary'], dtype=object),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array([2, 3, 4, 5, 6, 7]),\n",
       " array([1, 2, 3, 4, 5, 6, 7]),\n",
       " array([2, 3, 4, 5, 6, 7]),\n",
       " array([1, 2, 3, 4, 5, 6, 7]),\n",
       " array([1, 2, 3, 4, 5, 6, 7]),\n",
       " array(['Argentina/Brazil', 'Australia/New Zealand', 'Austria/Germany',\n",
       "        'Canada/Iceland/Russia', 'Carribean Islands', 'China/Taiwan',\n",
       "        'Colombia/Ecuador', 'Czech Republic/Hungary',\n",
       "        'Egypt/Jordan/Lebanon', 'France', 'Germany',\n",
       "        'Indonesia/Malaysia/Philippines', 'Italy/Malta',\n",
       "        'Japan/South Korea', 'Mexico/Costa Rica/El Salvador',\n",
       "        'Morocco/Tunisia/Senegal', 'Netherlands', 'Pakistan/India/Nepal',\n",
       "        'South Africa/Kenya/Namibia', 'Spain/Portugal', 'Sweden/Norway',\n",
       "        'Switzerland', 'United Kingdom/Ireland', 'United States',\n",
       "        'Vietnam/Cambodia/Thailand'], dtype=object)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(result_filtered, \"Recommendation\")\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(result_filtered,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = DecisionTreeClassifier()\n",
    "features = [\"Ideal Group Size\",\"Openness\",\"Conscientiousness\",\"Extraversion\",\"Agreeableness\",\"Neuroticism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-a5de1cdeb850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Recommendation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    156\u001b[0m             X, y = self._validate_data(X, y,\n\u001b[1;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[0;32m--> 158\u001b[0;31m                                                             check_y_params))\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;31m# When all dataframe columns are sparse, convert to a sparse array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sparse'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;31m# DataFrame.sparse only supports `to_coo`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_coo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "x_train = train[features]\n",
    "y_train = train['Recommendation']\n",
    "\n",
    "x_test = test[features]\n",
    "y_test = test['Recommendation']\n",
    "c.fit(enc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
